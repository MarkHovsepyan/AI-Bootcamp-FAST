{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ARS implementation.ipynb","provenance":[{"file_id":"115nEnUmyib_OJDvnu4gSFdQkFeiD_lYs","timestamp":1578938055878}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"vKiPAABHnGNd","colab_type":"code","outputId":"19bd5fb3-ab68-4d4c-8080-68cdb89c9bad","executionInfo":{"status":"ok","timestamp":1578937738320,"user_tz":-240,"elapsed":3271,"user":{"displayName":"Vardan Harutyunyan","photoUrl":"","userId":"17088512395548242923"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["#Cartpole\n","\n","import numpy as np\n","import gym\n","\n","np.random.seed(0)\n","\n","env = gym.make(\"CartPole-v1\")\n","print(env.action_space)\n","n_actions = env.action_space.n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Discrete(2)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kTRGcHIFLdiA","colab_type":"code","colab":{}},"source":["def sigmoid_action(state,weight):\n","    state = np.hstack((np.ones(1),state)) #Add 1 to the matrix\n","    sigmoid = 1/(1+np.exp(-(np.dot(state.T,weight)))) #Calculate sigmoid\n","    probs = np.array([1-sigmoid,sigmoid]) #Create probability distribution\n","    action = np.random.choice(np.arange(0,2),p=probs) #Choose action\n","    return action\n","\n","def play_episode(w, t_max=1000):\n","  states, actions = [], []\n","  total_reward = 0\n","\n","  s = env.reset()\n","  for t in range(t_max):\n","    action = sigmoid_action(s,w)\n","    new_s, r, done, info = env.step(action)\n","\n","    states.append(s)\n","    actions.append(action)\n","    total_reward += r\n","\n","    s = new_s\n","    if done:\n","        break\n","  return states, actions, total_reward"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mMEIujFSo4Df","colab_type":"code","colab":{}},"source":["# hyperparameters\n","npop = 8 # population size\n","sigma = 0.1 # noise standard deviation\n","alpha = 0.02 # learning rate\n","top_perf = 4 # Top performing directions to choose from\n","\n","w = np.zeros(5) # Our initial parameters are 0-s\n","for i in range(10000):\n","\n","  # print weight and reward every 50 iterations\n","  if i%50==0:\n","    print('iter %d. w: %s, reward: %f' % \n","          (i, str(w), play_episode(w)[2]))\n","\n","  # initialize memory for a population of w's, and their rewards\n","  N = np.random.randn(npop, 5) # samples from a normal distribution N(0,1)\n","  R_plus = np.zeros(npop) # Create arrays filled with zeros for R+\n","  R_minus = np.zeros(npop) # Create arrays filled with zeros for R-\n","  for j in range(npop):\n","    w_plus = w + sigma*N[j] # jitter w+ using gaussian of sigma 0.1\n","    w_minus = w - sigma*N[j] # jitter w- using gaussian of sigma 0.1\n","    R_plus[j] = play_episode(w_plus)[2] # Evaluate parameters w+\n","    R_minus[j] = play_episode(w_minus)[2] #Evaluate parameters for w-\n","\n","  # Calculate standart deviations\n","  all_rewards = np.array(R_minus + R_plus) \n","  sigma_r = all_rewards.std()\n","  \n","  #Choose best performing directions\n","  merged = np.array([R_plus,R_minus]).T\n","  best_indx = np.argsort(-np.amax(merged,1))[:top_perf]\n","  R_plus = R_plus[best_indx]\n","  R_minus = R_minus[best_indx]\n","  N = N[best_indx]\n","  \n","  # perform the parameter update.\n","  w = w + (alpha)/(sigma_r*top_perf) * np.dot(N.T, (R_plus-R_minus))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"b-SIIw8EBbJQ","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}